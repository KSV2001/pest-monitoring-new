# @package _global_

# to execute this experiment run:
# python run.py experiment=default.yaml

seed: 12345

hydra:
  run:
    dir: /output/${hydra.job.config_name}_${now:%m-%d_%H-%M}

trainer:
  _target_: pytorch_lightning.Trainer
  gpus: 2
  min_epochs: 1
  max_epochs: 10
  gradient_clip_val: 0.5
  accumulate_grad_batches: 2
  weights_summary: null

model:
  _target_: src.models.base.Model
  network:
    _target_: src.networks.trial.modules.simple_dense_net.ConvNet
  optimizer:
    _target_: torch.optim.SGD
    lr: 0.01
    momentum: 0.9
  loss:
    _target_: torch.nn.CrossEntropyLoss
  metrics:
    - _target_: torchmetrics.Accuracy
    - _target_: torchmetrics.Precision
      num_classes: 10

datamodule:
  _target_: src.data.trial.mnist_datamodule.MNISTDataModule
  data_dir: "/data/"
  batch_size: 64
  train_val_test_split: [55_000, 5_000, 10_000]
  num_workers: 0
  pin_memory: False

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/loss"
    mode: "min"
    dirpath: "checkpoints/"
    filename: "sample-mnist-{epoch:02d}"

logger:
  wandb:
    _target_: pytorch_lightning.loggers.wandb.WandbLogger
    project: "pest-monitoring-new"
    notes: "Description of this model."
